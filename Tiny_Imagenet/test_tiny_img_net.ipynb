{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "27085e40",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from datasets import load_dataset\n",
    "import torchvision.transforms as transforms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "69d08250",
   "metadata": {},
   "outputs": [],
   "source": [
    "class DataManager:\n",
    "    \"\"\"\n",
    "    Manager for Tiny ImageNet (zh-plus/tiny-imagenet) via Hugging Face Datasets.\n",
    "    \"\"\"\n",
    "    def __init__(self, batch_size, num_workers=2):\n",
    "        self.batch_size = batch_size\n",
    "        self.num_workers = num_workers\n",
    "\n",
    "        # Transforms cho train và valid\n",
    "        self.transform_train = transforms.Compose([\n",
    "            transforms.Lambda(lambda img: img.convert(\"RGB\") if img.mode != \"RGB\" else img),\n",
    "            transforms.RandomCrop(64, padding=4),\n",
    "            transforms.RandomHorizontalFlip(),\n",
    "            transforms.ToTensor(),\n",
    "            transforms.Normalize(mean=[0.485, 0.456, 0.406],\n",
    "                                 std=[0.229, 0.224, 0.225])\n",
    "        ])\n",
    "        self.transform_valid = transforms.Compose([\n",
    "            transforms.Lambda(lambda img: img.convert(\"RGB\") if img.mode != \"RGB\" else img),\n",
    "            transforms.ToTensor(),\n",
    "            transforms.Normalize(mean=[0.485, 0.456, 0.406],\n",
    "                                 std=[0.229, 0.224, 0.225])\n",
    "        ])\n",
    "\n",
    "    def get_loaders(self):\n",
    "        # 1) Load dataset\n",
    "        ds = load_dataset(\"zh-plus/tiny-imagenet\")\n",
    "        train_ds, valid_ds = ds[\"train\"], ds[\"valid\"]\n",
    "\n",
    "        # 2) Nếu nhãn là string, ánh xạ sang số nguyên\n",
    "        label_feature = train_ds.features[\"label\"]\n",
    "        class2idx = None\n",
    "        if hasattr(label_feature, 'names'):\n",
    "            class2idx = {name: idx for idx, name in enumerate(label_feature.names)}\n",
    "\n",
    "        # 3) preprocess per-sample cho train\n",
    "        def preprocess_train(ex):\n",
    "            img = ex[\"image\"]\n",
    "            img = self.transform_train(img)\n",
    "            lbl = ex[\"label\"]\n",
    "            if class2idx and isinstance(lbl, str):\n",
    "                lbl = class2idx[lbl]\n",
    "            return {\"image\": img, \"label\": lbl}\n",
    "\n",
    "        # 4) preprocess per-sample cho valid\n",
    "        def preprocess_valid(ex):\n",
    "            img = ex[\"image\"]\n",
    "            img = self.transform_valid(img)\n",
    "            lbl = ex[\"label\"]\n",
    "            if class2idx and isinstance(lbl, str):\n",
    "                lbl = class2idx[lbl]\n",
    "            return {\"image\": img, \"label\": lbl}\n",
    "\n",
    "        train_ds = train_ds.map(preprocess_train, batched=False)\n",
    "        valid_ds = valid_ds.map(preprocess_valid, batched=False)\n",
    "\n",
    "        # 5) Chuyển sang tensor cho PyTorch\n",
    "        train_ds.set_format(type=\"torch\", columns=[\"image\", \"label\"])\n",
    "        valid_ds.set_format(type=\"torch\", columns=[\"image\", \"label\"])\n",
    "\n",
    "        # 6) Tạo DataLoader\n",
    "        train_loader = torch.utils.data.DataLoader(\n",
    "            train_ds, batch_size=self.batch_size, shuffle=True, num_workers=self.num_workers\n",
    "        )\n",
    "        valid_loader = torch.utils.data.DataLoader(\n",
    "            valid_ds, batch_size=self.batch_size, shuffle=False, num_workers=self.num_workers\n",
    "        )\n",
    "\n",
    "        return train_loader, valid_loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "06f5cdad",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\ThucHanhML_lab\\.conda\\Lib\\site-packages\\huggingface_hub\\file_download.py:140: UserWarning: `huggingface_hub` cache-system uses symlinks by default to efficiently store duplicated files but your machine does not support them in D:\\huggingface\\huggingface_cache\\hub\\datasets--zh-plus--tiny-imagenet. Caching files will still work but in a degraded version that might require more space on your disk. This warning can be disabled by setting the `HF_HUB_DISABLE_SYMLINKS_WARNING` environment variable. For more details, see https://huggingface.co/docs/huggingface_hub/how-to-cache#limitations.\n",
      "To support symlinks on Windows, you either need to activate Developer Mode or to run Python as an administrator. In order to activate developer mode, see this article: https://docs.microsoft.com/en-us/windows/apps/get-started/enable-your-device-for-development\n",
      "  warnings.warn(message)\n",
      "Generating train split: 100%|██████████| 100000/100000 [00:02<00:00, 39498.64 examples/s]\n",
      "Generating valid split: 100%|██████████| 10000/10000 [00:00<00:00, 31081.21 examples/s]\n",
      "Map: 100%|██████████| 100000/100000 [03:19<00:00, 502.11 examples/s]\n",
      "Map: 100%|██████████| 10000/10000 [00:37<00:00, 266.29 examples/s]\n"
     ]
    }
   ],
   "source": [
    "data_manager = DataManager(2, 2)\n",
    "trainloader, testloader = data_manager.get_loaders()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "5867f904",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'image': tensor([[[[2.0777, 2.1290, 2.1462,  ..., 2.2318, 2.2318, 2.2318],\n",
      "          [2.1633, 2.1462, 2.1633,  ..., 2.2318, 2.2318, 2.2318],\n",
      "          [2.1975, 2.1975, 2.1633,  ..., 2.2147, 2.2147, 2.2147],\n",
      "          ...,\n",
      "          [1.2728, 1.9578, 2.2318,  ..., 1.6838, 1.6667, 1.5982],\n",
      "          [2.0434, 2.0777, 1.8037,  ..., 2.1462, 2.1119, 1.9920],\n",
      "          [2.0092, 1.9407, 2.0263,  ..., 2.2318, 2.2318, 2.1975]],\n",
      "\n",
      "         [[2.4111, 2.4111, 2.4286,  ..., 2.4111, 2.4111, 2.4111],\n",
      "          [2.4286, 2.4286, 2.4111,  ..., 2.4111, 2.4111, 2.4111],\n",
      "          [2.4286, 2.4286, 2.4111,  ..., 2.3936, 2.3936, 2.3936],\n",
      "          ...,\n",
      "          [1.4482, 2.1485, 2.4286,  ..., 1.8508, 1.8333, 1.7633],\n",
      "          [2.4286, 2.4286, 2.1835,  ..., 2.3235, 2.2885, 2.2185],\n",
      "          [2.4286, 2.4286, 2.4286,  ..., 2.4111, 2.4111, 2.4286]],\n",
      "\n",
      "         [[2.5703, 2.5877, 2.6051,  ..., 2.6226, 2.6226, 2.6226],\n",
      "          [2.6226, 2.6051, 2.6051,  ..., 2.6226, 2.6226, 2.6226],\n",
      "          [2.6400, 2.6400, 2.6051,  ..., 2.6051, 2.6051, 2.6051],\n",
      "          ...,\n",
      "          [1.6988, 2.3960, 2.6400,  ..., 2.2391, 2.2217, 2.1520],\n",
      "          [2.6400, 2.6400, 2.3263,  ..., 2.6400, 2.6400, 2.5877],\n",
      "          [2.6400, 2.6051, 2.6400,  ..., 2.6400, 2.6400, 2.6400]]],\n",
      "\n",
      "\n",
      "        [[[0.6906, 0.6734, 0.6392,  ..., 0.5022, 0.5193, 0.5878],\n",
      "          [0.6734, 0.6563, 0.6392,  ..., 0.5536, 0.6221, 0.6906],\n",
      "          [0.8618, 0.8447, 0.8104,  ..., 0.4851, 0.5022, 0.5193],\n",
      "          ...,\n",
      "          [0.3309, 0.3652, 0.3994,  ..., 0.5022, 0.3138, 0.1083],\n",
      "          [0.3481, 0.3823, 0.4166,  ..., 0.6049, 0.4337, 0.1768],\n",
      "          [0.2624, 0.2967, 0.3652,  ..., 0.6734, 0.5193, 0.2282]],\n",
      "\n",
      "         [[1.0630, 1.0455, 1.0105,  ..., 0.8354, 0.8529, 0.9230],\n",
      "          [1.0455, 1.0280, 1.0105,  ..., 0.8880, 0.9580, 1.0280],\n",
      "          [1.2381, 1.2206, 1.1856,  ..., 0.8179, 0.8354, 0.8529],\n",
      "          ...,\n",
      "          [0.6779, 0.7129, 0.7479,  ..., 0.8704, 0.6954, 0.4853],\n",
      "          [0.6954, 0.7304, 0.7654,  ..., 0.9755, 0.8004, 0.5378],\n",
      "          [0.6078, 0.6429, 0.7129,  ..., 1.0455, 0.8880, 0.6429]],\n",
      "\n",
      "         [[1.1237, 1.1062, 1.0714,  ..., 0.7576, 0.7751, 0.8448],\n",
      "          [1.1062, 1.0888, 1.0714,  ..., 0.8099, 0.8797, 0.9494],\n",
      "          [1.2980, 1.2805, 1.2457,  ..., 0.7402, 0.7576, 0.7751],\n",
      "          ...,\n",
      "          [0.5136, 0.5485, 0.6182,  ..., 0.9145, 0.6879, 0.4788],\n",
      "          [0.5311, 0.5659, 0.6356,  ..., 1.0191, 0.8448, 0.5834],\n",
      "          [0.4439, 0.4788, 0.5834,  ..., 1.1062, 0.9319, 0.6705]]]]), 'label': tensor([0, 0])}\n"
     ]
    }
   ],
   "source": [
    "for i in testloader:\n",
    "    print(i)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d489332",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
